{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import triton\n",
    "triton.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from jiwer import wer, cer\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_benchmark = [    \n",
    "    \"ahmedheakl/arocrbench_synthesizear\",\n",
    "    \"ahmedheakl/arocrbench_patsocr\",\n",
    "    \"ahmedheakl/arocrbench_arabicocr\",\n",
    "    \"ahmedheakl/arocrbench_hindawi\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"NAMAA-Space/Qari-OCR-0.2.2-Arabic-2B-Instruct\", use_fast=True,)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"NAMAA-Space/Qari-OCR-0.2.2-Arabic-2B-Instruct\", torch_dtype=\"auto\", device_map=\"cuda:1\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Just return the plain text representation of this document as if you were reading it naturally. Do not hallucinate\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "text_prompt = processor.apply_chat_template(messages, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwen_extract_ocr(text_prompt, image):\n",
    "    image = resize_image(image, min_factor=28, max_size=(1024, 1024))\n",
    "    inputs = processor(text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(\"cuda:1\")\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=1024)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return \" \".join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(text):\n",
    "    diacritics = [\n",
    "        '\\u0617', '\\u0618', '\\u0619', '\\u061A',\n",
    "        '\\u064B', '\\u064C', '\\u064D', '\\u064E', '\\u064F', '\\u0650',\n",
    "        '\\u0651', '\\u0652', '\\u0653', '\\u0654', '\\u0655', '\\u0656',\n",
    "        '\\u0657', '\\u0658', '\\u0659', '\\u065A', '\\u065B', '\\u065C',\n",
    "        '\\u065D', '\\u065E', '\\u065F', '\\u0670'\n",
    "    ]\n",
    "    pattern = '[' + ''.join(diacritics) + ']'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def remove_english_letters(text):\n",
    "    pattern = r'[a-zA-Z]'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned = re.sub(r'[\\n\\t]+', ' ', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    return cleaned.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def resize_image(image, min_factor=28, max_size=(1024, 1024)):\n",
    "    width, height = image.size\n",
    "    factor = min_factor  # Must be divisible by this (processor's patch size * merge_size)\n",
    "    \n",
    "    # Calculate aspect ratio\n",
    "    aspect_ratio = width / height\n",
    "    \n",
    "    # Ensure dimensions are at least factor and divisible by factor\n",
    "    new_width = max(factor, width)\n",
    "    new_height = max(factor, height)\n",
    "    \n",
    "    # Adjust to be multiples of factor while preserving aspect ratio as closely as possible\n",
    "    new_width = math.ceil(new_width / factor) * factor\n",
    "    new_height = math.ceil(new_height / factor) * factor\n",
    "    \n",
    "    # Recalculate to maintain aspect ratio\n",
    "    if new_width / new_height > aspect_ratio:\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "        new_width = math.ceil(new_width / factor) * factor  # Ensure divisible by factor\n",
    "    else:\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "        new_height = math.ceil(new_height / factor) * factor  # Ensure divisible by factor\n",
    "    \n",
    "    # Ensure within max_size\n",
    "    if new_width > max_size[0] or new_height > max_size[1]:\n",
    "        if new_width > max_size[0]:\n",
    "            new_width = max_size[0] - (max_size[0] % factor)  # Largest multiple of factor <= max_size[0]\n",
    "            new_height = int(new_width / aspect_ratio)\n",
    "            new_height = math.ceil(new_height / factor) * factor\n",
    "        if new_height > max_size[1]:\n",
    "            new_height = max_size[1] - (max_size[1] % factor)  # Largest multiple of factor <= max_size[1]\n",
    "            new_width = int(new_height * aspect_ratio)\n",
    "            new_width = math.ceil(new_width / factor) * factor\n",
    "    \n",
    "    # Resize if necessary\n",
    "    if (new_width, new_height) != (width, height):\n",
    "        image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_dataset(dataset_name, split=\"train\"):\n",
    "    print(f\"Loading dataset: {dataset_name}\")\n",
    "    dataset = load_dataset(dataset_name, split=split)\n",
    "    \n",
    "    results = []\n",
    "    sample_keys = dataset[0].keys()  \n",
    "    ground_truth_key = \"text\" if \"text\" in sample_keys else \"answer\" if \"answer\" in sample_keys else None\n",
    "    if ground_truth_key is None:\n",
    "        raise ValueError(f\"No suitable ground truth key ('text' or 'answer') found in dataset: {dataset_name}\")\n",
    "    \n",
    "    # Prepare samples\n",
    "    for sample in tqdm(dataset, desc=f\"Preparing samples from {dataset_name}\"):\n",
    "        image = sample[\"image\"]\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        ground_truth = sample[ground_truth_key]\n",
    "        results.append({\n",
    "            \"dataset\": dataset_name,\n",
    "            \"image\": image,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"qari2\": None,\n",
    "            \"status\": \"pending\"  # Add status to track processing outcome\n",
    "        })\n",
    "    \n",
    "    skipped_samples = 0\n",
    "    for i, sample in tqdm(enumerate(results), total=len(results), desc=f\"Running Qari on {dataset_name}\"):\n",
    "        # torch.cuda.empty_cache()\n",
    "        image = sample[\"image\"]\n",
    "        try:\n",
    "            text_result = qwen_extract_ocr(text_prompt, image)\n",
    "            results[i][\"qari2\"] = text_result\n",
    "            results[i][\"status\"] = \"success\"\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" in str(e):\n",
    "                print(f\"Skipping sample {i} in {dataset_name} due to CUDA out of memory error.\")\n",
    "                results[i][\"qari2\"] = \"Skipped - CUDA OOM\"\n",
    "                results[i][\"status\"] = \"skipped\"\n",
    "                skipped_samples += 1\n",
    "            else:\n",
    "                print(f\"Error processing sample {i} in {dataset_name}: {str(e)}\")\n",
    "                results[i][\"qari2\"] = f\"Error - {str(e)}\"\n",
    "                results[i][\"status\"] = \"error\"\n",
    "    \n",
    "    print(f\"Processed {len(results) - skipped_samples} samples successfully, skipped {skipped_samples} due to memory issues in {dataset_name}.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: ahmedheakl/arocrbench_synthesizear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing samples from ahmedheakl/arocrbench_synthesizear: 100%|██████████| 500/500 [00:00<00:00, 875.17it/s]\n",
      "Running Qari on ahmedheakl/arocrbench_synthesizear: 100%|██████████| 500/500 [54:43<00:00,  6.57s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 samples successfully, skipped 0 due to memory issues in ahmedheakl/arocrbench_synthesizear.\n",
      "Loading dataset: ahmedheakl/arocrbench_patsocr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing samples from ahmedheakl/arocrbench_patsocr: 100%|██████████| 500/500 [00:00<00:00, 685.52it/s]\n",
      "Running Qari on ahmedheakl/arocrbench_patsocr: 100%|██████████| 500/500 [1:00:41<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 samples successfully, skipped 0 due to memory issues in ahmedheakl/arocrbench_patsocr.\n",
      "Loading dataset: ahmedheakl/arocrbench_arabicocr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing samples from ahmedheakl/arocrbench_arabicocr: 100%|██████████| 50/50 [00:00<00:00, 781.64it/s]\n",
      "Running Qari on ahmedheakl/arocrbench_arabicocr: 100%|██████████| 50/50 [10:11<00:00, 12.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 samples successfully, skipped 0 due to memory issues in ahmedheakl/arocrbench_arabicocr.\n",
      "Loading dataset: ahmedheakl/arocrbench_hindawi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing samples from ahmedheakl/arocrbench_hindawi: 100%|██████████| 200/200 [00:01<00:00, 140.61it/s]\n",
      "Running Qari on ahmedheakl/arocrbench_hindawi: 100%|██████████| 200/200 [2:44:45<00:00, 49.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 samples successfully, skipped 0 due to memory issues in ahmedheakl/arocrbench_hindawi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for dataset_name in datasets_to_benchmark:\n",
    "    dataset_results = benchmark_dataset(dataset_name)\n",
    "    all_results.extend(dataset_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>qari2</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dataset, image, ground_truth, qari2, status]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['status']!='success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"uncleand_qari2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>image</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>qari2</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ahmedheakl/arocrbench_synthesizear</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=639x114 at 0x775534276B10&gt;</td>\n",
       "      <td>وَإِذا ما سَأَلَتْنِي عَن مَعْنَى لَفَظَهُ \"عرب\" عِنْدَ</td>\n",
       "      <td>وَإِذا ما سَأَلْتَنِي عَن مَعْنَى لَفْظَهُ \"عرب\" عِنْدَ</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ahmedheakl/arocrbench_synthesizear</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1182x147 at 0x775534276ED0&gt;</td>\n",
       "      <td>أَمّا فَهُم النُصُوصِ وَاِسْتِنْباط مَعانِيها بِوَجْهٍ صَحِيحٌ دقيق،</td>\n",
       "      <td>أمّا فَهْم النُّصوصِ وَإِسْتِنْباطِ مَعانِيها بِوَجْهٍ ضَحِيحٌ دقيقٍ،</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ahmedheakl/arocrbench_synthesizear</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=994x163 at 0x775534277450&gt;</td>\n",
       "      <td>تُثِير فِيها الاسود، وَهُوَ ما يَتَعارَض مَعَ اِكْتِشافِ</td>\n",
       "      <td>تُثِير فِيها الاسود، وَهْوَ ما يَتَعارَض مَعَ إِكْتِشافِ</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahmedheakl/arocrbench_synthesizear</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1315x224 at 0x7755342779D0&gt;</td>\n",
       "      <td>الجماعي، وَكادَت تَصِل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّة لِسَيْطَرَةِ أَكْبَرَ</td>\n",
       "      <td>وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى الم</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahmedheakl/arocrbench_synthesizear</td>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1224x129 at 0x775534277F50&gt;</td>\n",
       "      <td>مَعَهُ مَنْدِيلا فِيهِ جردقتان وَقَطَعَ لَحْم سَكْباج مُبَرَّد</td>\n",
       "      <td>مَعَهْ مَنْدِيلا فِيهِ جردقتان وَقَطَعَ لَحْم سَكْباج مْبَرَّد</td>\n",
       "      <td>success</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              dataset  \\\n",
       "0  ahmedheakl/arocrbench_synthesizear   \n",
       "1  ahmedheakl/arocrbench_synthesizear   \n",
       "2  ahmedheakl/arocrbench_synthesizear   \n",
       "3  ahmedheakl/arocrbench_synthesizear   \n",
       "4  ahmedheakl/arocrbench_synthesizear   \n",
       "\n",
       "                                                                                image  \\\n",
       "0   <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=639x114 at 0x775534276B10>   \n",
       "1  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1182x147 at 0x775534276ED0>   \n",
       "2   <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=994x163 at 0x775534277450>   \n",
       "3  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1315x224 at 0x7755342779D0>   \n",
       "4  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1224x129 at 0x775534277F50>   \n",
       "\n",
       "                                                                       ground_truth  \\\n",
       "0                           وَإِذا ما سَأَلَتْنِي عَن مَعْنَى لَفَظَهُ \"عرب\" عِنْدَ   \n",
       "1              أَمّا فَهُم النُصُوصِ وَاِسْتِنْباط مَعانِيها بِوَجْهٍ صَحِيحٌ دقيق،   \n",
       "2                          تُثِير فِيها الاسود، وَهُوَ ما يَتَعارَض مَعَ اِكْتِشافِ   \n",
       "3  الجماعي، وَكادَت تَصِل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّة لِسَيْطَرَةِ أَكْبَرَ   \n",
       "4                    مَعَهُ مَنْدِيلا فِيهِ جردقتان وَقَطَعَ لَحْم سَكْباج مُبَرَّد   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     qari2  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  وَإِذا ما سَأَلْتَنِي عَن مَعْنَى لَفْظَهُ \"عرب\" عِنْدَ   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    أمّا فَهْم النُّصوصِ وَإِسْتِنْباطِ مَعانِيها بِوَجْهٍ ضَحِيحٌ دقيقٍ،   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 تُثِير فِيها الاسود، وَهْوَ ما يَتَعارَض مَعَ إِكْتِشافِ   \n",
       "3  وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى المَرْحَلَةِ الاِشْتِراكِيَّةِ لِسَيْطَرَةِ أَكْبَرَ الجماعي، وَكَادَت تَصل إِلَى الم   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           مَعَهْ مَنْدِيلا فِيهِ جردقتان وَقَطَعَ لَحْم سَكْباج مْبَرَّد   \n",
       "\n",
       "    status  \n",
       "0  success  \n",
       "1  success  \n",
       "2  success  \n",
       "3  success  \n",
       "4  success  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer = load('cer')\n",
    "wer = load('wer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluatemodel(dataset):\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        preds.append(dataset.iloc[i]['qari2'])\n",
    "        refs.append(dataset.iloc[i]['ground_truth'])\n",
    "\n",
    "    wer_score = wer.compute(predictions=preds, references=refs)\n",
    "\n",
    "    cer_score = cer.compute(predictions=preds, references=refs)\n",
    "    return {\"wer\": wer_score, \"cer\": cer_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahmedheakl/arocrbench_synthesizear\n",
      "{'wer': 0.9248366013071896, 'cer': 0.7236747667384394}\n",
      "ahmedheakl/arocrbench_patsocr\n",
      "{'wer': 1.1536427025727338, 'cer': 1.1630813307318038}\n",
      "ahmedheakl/arocrbench_arabicocr\n",
      "{'wer': 0.0694304010785305, 'cer': 0.016119812507145306}\n",
      "ahmedheakl/arocrbench_hindawi\n",
      "{'wer': 0.49612378770283416, 'cer': 0.28948339582074223}\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets_to_benchmark:\n",
    "    subset_df = df[df[\"dataset\"] == dataset_name]\n",
    "    print(dataset_name)\n",
    "    print(evaluatemodel(subset_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahmedheakl/arocrbench_synthesizear\n",
      "{'wer': 0.9248366013071896, 'cer': 0.7236747667384394}\n",
      "ahmedheakl/arocrbench_patsocr\n",
      "{'wer': 1.1536427025727338, 'cer': 1.1630813307318038}\n",
      "ahmedheakl/arocrbench_arabicocr\n",
      "{'wer': 0.0694304010785305, 'cer': 0.016119812507145306}\n",
      "ahmedheakl/arocrbench_hindawi\n",
      "{'wer': 0.49612378770283416, 'cer': 0.28948339582074223}\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets_to_benchmark:\n",
    "    subset_df = df[df[\"dataset\"] == dataset_name]\n",
    "    print(dataset_name)\n",
    "    print(evaluatemodel(subset_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 0.6195266777735059, 'cer': 0.44736391053669955}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatemodel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 0.6195266777735059, 'cer': 0.44736391053669955}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatemodel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"uncleand_qari2.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ground_truth\"] = df[\"ground_truth\"].astype(str).fillna(\"\").apply(remove_english_letters).apply(clean_text).astype(str)\n",
    "df[\"qari2\"] = df[\"qari2\"].astype(str).fillna(\"\").apply(remove_english_letters).apply(clean_text).astype(str)\n",
    "df[\"ground_truth_t\"] = df[\"ground_truth\"].astype(str).fillna(\"\").apply(remove_diacritics).astype(str)\n",
    "df[\"qari2_t\"] = df[\"qari2\"].astype(str).fillna(\"\").apply(remove_diacritics).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m].unique()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ahmedheakl/arocrbench_synthesizear:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'WER' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m subset_df = df[df[\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m] == dataset_name]\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResults for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m wer_score = \u001b[43mwer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqari2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m cer_score = cer(subset_df[\u001b[33m\"\u001b[39m\u001b[33mground_truth\u001b[39m\u001b[33m\"\u001b[39m].tolist(), subset_df[\u001b[33m\"\u001b[39m\u001b[33mqari2\u001b[39m\u001b[33m\"\u001b[39m].tolist())\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQari2 - WER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwer_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, CER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcer_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'WER' object is not callable"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets_to_benchmark:\n",
    "    subset_df = df[df[\"dataset\"] == dataset_name]\n",
    "    print(f\"\\nResults for {dataset_name}:\")\n",
    "    \n",
    "    wer_score = wer(subset_df[\"ground_truth\"].tolist(), subset_df[\"qari2\"].tolist())\n",
    "    cer_score = cer(subset_df[\"ground_truth\"].tolist(), subset_df[\"qari2\"].tolist())\n",
    "    print(f\"Qari2 - WER: {wer_score:.2f}, CER: {cer_score:.2f}\")\n",
    "    \n",
    "    wer_score_t = wer(subset_df[\"ground_truth_t\"].tolist(), subset_df[\"qari2_t\"].tolist())\n",
    "    cer_score_t = cer(subset_df[\"ground_truth_t\"].tolist(), subset_df[\"qari2_t\"].tolist())\n",
    "    print(f\"Qari2 (no diacritics) - WER: {wer_score_t:.2f}, CER: {cer_score_t:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"qari2_ocr_benchmark_results.csv\", index=False)\n",
    "print(\"Results saved to 'qari2_ocr_benchmark_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSample of results:\")\n",
    "print(df[[\"dataset\", \"ground_truth\", \"qari2\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
